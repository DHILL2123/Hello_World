{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6247a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'acquire'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#stored functions and local credentials you will need to access the data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#stored in mysql or on you local device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01macquire\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_telco_data\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprepare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prep_telco, prep_telco_encode, telco_train_validate_test_split\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m host,db,protocol,password,user,mysqlcon\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'acquire'"
     ]
    }
   ],
   "source": [
    "#import packages and libraries that assist with analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "#stored functions and local credentials you will need to access the data\n",
    "#stored in mysql or on you local device\n",
    "import os\n",
    "from acquire import get_telco_data\n",
    "from prepare import prep_telco, prep_telco_encode, telco_train_validate_test_split\n",
    "from env import host,db,protocol,password,user,mysqlcon\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"student_grades.csv\"\n",
    "os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6657586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aquire_student_grades():\n",
    "    filename = \"student_grades.csv\"\n",
    "\n",
    "    mysqlcon=f\"{protocol}://{user}:{password}@{host}/{db}\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "      # Write that dataframe to disk for later. Called \"caching\" the data for later.\n",
    "        df.to_csv(filename)\n",
    "        return df\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3ca85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=aquire_student_grades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068afe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='student_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4587f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exam3'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b54ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exam1'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exam1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exam1'] = df.exam1.astype(int)\n",
    "df['exam3'] = df.exam3.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a950c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_student_grades(df):\n",
    "    '''\n",
    "    clean_student_grades(df) takes in a single pandas dataframe\n",
    "    removed the student id columns, removes records with null values, and cast any floats\n",
    "    into integers.Returns a clead df.\n",
    "    '''\n",
    "    #drops student_id column\n",
    "    df = df.drop(columns='student_id')\n",
    "    #drops na values \n",
    "    df = df.dropna()\n",
    "    #turn whole df into a integer. float values match int values\n",
    "    df = df.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_my_students(df):\n",
    "    '''\n",
    "    split_my_students(df) takes in a a clean dataframe, referencing the cleaned\n",
    "    version of student data. Split the data into train, validate, test\n",
    "    \n",
    "    pass df as an arguement in the function \n",
    "    returns: train, validate, test: three pandas dataframes\n",
    "    '''\n",
    "    train_val, test = train_test_split(df, random_state=1349, train_size=0.7)\n",
    "    \n",
    "    train, validate = train_test_split(train_val, random_state=1349, train_size=.10)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_grades():\n",
    "    '''\n",
    "    wrangle_grades does the split and clean and returns the data'''\n",
    "    return split_my_students(\n",
    "        clean_student_grades(\n",
    "            aquire_student_grades()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle_grades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e116459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc7dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe51ee9",
   "metadata": {},
   "source": [
    "### Exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow_data():\n",
    "    filename = \"zillow.csv\"\n",
    "    mysqlcon=f\"{protocol}://{user}:{password}@{host}/{db}\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        # read the SQL query into a dataframe\n",
    "        df = pd.read_sql(df = pd.read_sql_query(\"select * from properties_2017\", mysqlcon))\n",
    "        # Write that dataframe to disk for later. Called \"caching\" the data for later.\n",
    "        df.to_csv(filename)\n",
    "        # Return the dataframe to the calling code\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3e9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
